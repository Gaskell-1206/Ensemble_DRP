{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3aba53-7979-4126-8e8a-74bde78d1d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from DataModule.Data_Preparation import CoronnaCERTAINDataset\n",
    "import EvaluationModule\n",
    "from ModelModule import models\n",
    "\n",
    "import xgboost as xgb\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bc84701-0a30-403f-a201-784a6ca9bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CoronnaCERTAINDataset(\n",
    "    library_root = '/Users/gaskell/Dropbox/Mac/Desktop/Autoimmune_Disease/Code/ML_RA_EHR/Dataset/',\n",
    "    challenge = 'regression_delta_binary', #option: regression, regression_delta, classification, binary_classification, regression_delta_binary\n",
    "    dataset = 'CORRONA CERTAIN', \n",
    "    process_approach = 'SC', #option: KVB, SC\n",
    "    imputation = 'IterativeImputer', #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "    patient_group = ['bionaive TNF'], #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "    drug_group = 'all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "    time_points = (0,3), \n",
    "    train_test_rate = 0.8,\n",
    "    remove_low_DAS = True,\n",
    "    save_csv = False, \n",
    "    random_state = 2022,\n",
    "    verbose=False)\n",
    "\n",
    "# read train, test from dataloader\n",
    "train_set, train_loc = dataset.get_train()\n",
    "test_set, test_loc = dataset.get_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80c4c84-0fd1-4e6d-973d-1be6e8d7fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_builder = models.make_models(\"SC_Jul24_test\",['Linear','Ridge','Lasso','SVM','KNN','XGBoost','Random Forest'],[],'Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fa896b-fbd1-4d4b-bea4-8ffdd441c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in model_builder.model_dict:\n",
    "#     print(model_builder.model_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6edf236a-9970-4e6a-94c3-f0149ef8013a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_search_grid: {'max_samples': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, None], 'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "best_params: {'n_estimators': 1100, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_samples': None, 'max_features': 'log2', 'max_depth': 40, 'bootstrap': False}\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       198\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       203\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       203\n",
      "dtype: int64\n",
      "before sampling: Responder       207\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    207\n",
      "Responder       202\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       203\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       203\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       202\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       201\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       202\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       203\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       204\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       200\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       198\n",
      "dtype: int64\n",
      "before sampling: Responder       207\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    207\n",
      "Responder       203\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       206\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       199\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       204\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       204\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       205\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       205\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       205\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       202\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     65\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       205\n",
      "dtype: int64\n",
      "before sampling: Responder       207\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    207\n",
      "Responder       199\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       205\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       206\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       201\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       202\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       201\n",
      "dtype: int64\n",
      "before sampling: Responder       208\n",
      "Nonresponder     66\n",
      "dtype: int64\n",
      "after sampling: Nonresponder    208\n",
      "Responder       205\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "aml = EvaluationModule.AutoBuild(seed=dataset.random_state, project_name=\"SC_Jul24_test\", challenge=dataset.challenge, balance_class=2)\n",
    "# define models\n",
    "if \"regression\" in dataset.challenge:\n",
    "#     for key in model_builder.model_dict:\n",
    "#         model = model_builder.model_dict[key]\n",
    "#         aml.validate(key, model, train_set, test_set)\n",
    "    model = FineTuneModule.fine_tune(train=train_set, model=\"drf_regression\", search_methods=\"RandomSearch\")\n",
    "elif \"classification\" in dataset.challenge:\n",
    "    model = FineTuneModule.fine_tune(train=train_set, model=\"drf_classification\", search_methods=\"RandomSearch\")\n",
    "    \n",
    "aml.validate('rf', model, train_set, test_set)\n",
    "# aml.validation_output(dataset)\n",
    "# aml.test_output(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb55402-19cd-48a9-9bb9-88bcbe18dada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Pearson_Correlation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084686</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>0.136816</td>\n",
       "      <td>0.979473</td>\n",
       "      <td>0.995321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.087420</td>\n",
       "      <td>0.019906</td>\n",
       "      <td>0.141087</td>\n",
       "      <td>0.978055</td>\n",
       "      <td>0.994860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084854</td>\n",
       "      <td>0.018899</td>\n",
       "      <td>0.137474</td>\n",
       "      <td>0.979299</td>\n",
       "      <td>0.995024</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.086161</td>\n",
       "      <td>0.019911</td>\n",
       "      <td>0.141108</td>\n",
       "      <td>0.976139</td>\n",
       "      <td>0.994365</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083758</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>0.136773</td>\n",
       "      <td>0.978545</td>\n",
       "      <td>0.995132</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083384</td>\n",
       "      <td>0.018025</td>\n",
       "      <td>0.134257</td>\n",
       "      <td>0.979231</td>\n",
       "      <td>0.995335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083345</td>\n",
       "      <td>0.019560</td>\n",
       "      <td>0.139855</td>\n",
       "      <td>0.975597</td>\n",
       "      <td>0.994196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084389</td>\n",
       "      <td>0.018556</td>\n",
       "      <td>0.136221</td>\n",
       "      <td>0.979482</td>\n",
       "      <td>0.994915</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.087105</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.137788</td>\n",
       "      <td>0.980388</td>\n",
       "      <td>0.995080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.086269</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.138065</td>\n",
       "      <td>0.979550</td>\n",
       "      <td>0.995139</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084086</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.137373</td>\n",
       "      <td>0.977950</td>\n",
       "      <td>0.994794</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.085073</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.138580</td>\n",
       "      <td>0.977212</td>\n",
       "      <td>0.994887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.086744</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.137764</td>\n",
       "      <td>0.979867</td>\n",
       "      <td>0.995443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084164</td>\n",
       "      <td>0.019524</td>\n",
       "      <td>0.139728</td>\n",
       "      <td>0.978647</td>\n",
       "      <td>0.994771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083743</td>\n",
       "      <td>0.018711</td>\n",
       "      <td>0.136789</td>\n",
       "      <td>0.979097</td>\n",
       "      <td>0.994973</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.082414</td>\n",
       "      <td>0.018721</td>\n",
       "      <td>0.136823</td>\n",
       "      <td>0.977827</td>\n",
       "      <td>0.994824</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.018603</td>\n",
       "      <td>0.136394</td>\n",
       "      <td>0.977633</td>\n",
       "      <td>0.994766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.086129</td>\n",
       "      <td>0.019872</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.977343</td>\n",
       "      <td>0.994765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084199</td>\n",
       "      <td>0.017410</td>\n",
       "      <td>0.131946</td>\n",
       "      <td>0.980978</td>\n",
       "      <td>0.995640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.084701</td>\n",
       "      <td>0.018137</td>\n",
       "      <td>0.134674</td>\n",
       "      <td>0.980415</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083966</td>\n",
       "      <td>0.017723</td>\n",
       "      <td>0.133128</td>\n",
       "      <td>0.979028</td>\n",
       "      <td>0.995381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.082602</td>\n",
       "      <td>0.018144</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.979590</td>\n",
       "      <td>0.995260</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.082530</td>\n",
       "      <td>0.018655</td>\n",
       "      <td>0.136581</td>\n",
       "      <td>0.978783</td>\n",
       "      <td>0.994937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>0.142161</td>\n",
       "      <td>0.977944</td>\n",
       "      <td>0.994842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.085601</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>0.144155</td>\n",
       "      <td>0.974856</td>\n",
       "      <td>0.993571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>0.018865</td>\n",
       "      <td>0.137349</td>\n",
       "      <td>0.979005</td>\n",
       "      <td>0.994802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.083230</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.134848</td>\n",
       "      <td>0.979796</td>\n",
       "      <td>0.995259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>0.020876</td>\n",
       "      <td>0.144484</td>\n",
       "      <td>0.977032</td>\n",
       "      <td>0.994163</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.085196</td>\n",
       "      <td>0.018729</td>\n",
       "      <td>0.136853</td>\n",
       "      <td>0.979689</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.086269</td>\n",
       "      <td>0.019564</td>\n",
       "      <td>0.139873</td>\n",
       "      <td>0.976638</td>\n",
       "      <td>0.994437</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model       MAE       MSE      RMSE        R2  Pearson_Correlation  \\\n",
       "0     rf  0.084686  0.018719  0.136816  0.979473             0.995321   \n",
       "1     rf  0.087420  0.019906  0.141087  0.978055             0.994860   \n",
       "2     rf  0.084854  0.018899  0.137474  0.979299             0.995024   \n",
       "3     rf  0.086161  0.019911  0.141108  0.976139             0.994365   \n",
       "4     rf  0.083758  0.018707  0.136773  0.978545             0.995132   \n",
       "5     rf  0.083384  0.018025  0.134257  0.979231             0.995335   \n",
       "6     rf  0.083345  0.019560  0.139855  0.975597             0.994196   \n",
       "7     rf  0.084389  0.018556  0.136221  0.979482             0.994915   \n",
       "8     rf  0.087105  0.018985  0.137788  0.980388             0.995080   \n",
       "9     rf  0.086269  0.019062  0.138065  0.979550             0.995139   \n",
       "10    rf  0.084086  0.018871  0.137373  0.977950             0.994794   \n",
       "11    rf  0.085073  0.019204  0.138580  0.977212             0.994887   \n",
       "12    rf  0.086744  0.018979  0.137764  0.979867             0.995443   \n",
       "13    rf  0.084164  0.019524  0.139728  0.978647             0.994771   \n",
       "14    rf  0.083743  0.018711  0.136789  0.979097             0.994973   \n",
       "15    rf  0.082414  0.018721  0.136823  0.977827             0.994824   \n",
       "16    rf  0.082211  0.018603  0.136394  0.977633             0.994766   \n",
       "17    rf  0.086129  0.019872  0.140969  0.977343             0.994765   \n",
       "18    rf  0.084199  0.017410  0.131946  0.980978             0.995640   \n",
       "19    rf  0.084701  0.018137  0.134674  0.980415             0.995274   \n",
       "20    rf  0.083966  0.017723  0.133128  0.979028             0.995381   \n",
       "21    rf  0.082602  0.018144  0.134700  0.979590             0.995260   \n",
       "22    rf  0.082530  0.018655  0.136581  0.978783             0.994937   \n",
       "23    rf  0.087967  0.020210  0.142161  0.977944             0.994842   \n",
       "24    rf  0.085601  0.020781  0.144155  0.974856             0.993571   \n",
       "25    rf  0.083142  0.018865  0.137349  0.979005             0.994802   \n",
       "26    rf  0.083230  0.018184  0.134848  0.979796             0.995259   \n",
       "27    rf  0.087879  0.020876  0.144484  0.977032             0.994163   \n",
       "28    rf  0.085196  0.018729  0.136853  0.979689             0.995122   \n",
       "29    rf  0.086269  0.019564  0.139873  0.976638             0.994437   \n",
       "\n",
       "    Accuracy  F1-Score  \n",
       "0        1.0       1.0  \n",
       "1        1.0       1.0  \n",
       "2        1.0       1.0  \n",
       "3        1.0       1.0  \n",
       "4        1.0       1.0  \n",
       "5        1.0       1.0  \n",
       "6        1.0       1.0  \n",
       "7        1.0       1.0  \n",
       "8        1.0       1.0  \n",
       "9        1.0       1.0  \n",
       "10       1.0       1.0  \n",
       "11       1.0       1.0  \n",
       "12       1.0       1.0  \n",
       "13       1.0       1.0  \n",
       "14       1.0       1.0  \n",
       "15       1.0       1.0  \n",
       "16       1.0       1.0  \n",
       "17       1.0       1.0  \n",
       "18       1.0       1.0  \n",
       "19       1.0       1.0  \n",
       "20       1.0       1.0  \n",
       "21       1.0       1.0  \n",
       "22       1.0       1.0  \n",
       "23       1.0       1.0  \n",
       "24       1.0       1.0  \n",
       "25       1.0       1.0  \n",
       "26       1.0       1.0  \n",
       "27       1.0       1.0  \n",
       "28       1.0       1.0  \n",
       "29       1.0       1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.train_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fb7bb77-32da-438f-a657-daf4a99d9e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Pearson_Correlation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.348017</td>\n",
       "      <td>12.649644</td>\n",
       "      <td>3.556634</td>\n",
       "      <td>-7.243906</td>\n",
       "      <td>0.311026</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.470257</td>\n",
       "      <td>13.222314</td>\n",
       "      <td>3.636250</td>\n",
       "      <td>-9.443264</td>\n",
       "      <td>0.326711</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.448496</td>\n",
       "      <td>13.310552</td>\n",
       "      <td>3.648363</td>\n",
       "      <td>-10.192320</td>\n",
       "      <td>0.149196</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.314047</td>\n",
       "      <td>12.410373</td>\n",
       "      <td>3.522836</td>\n",
       "      <td>-7.177222</td>\n",
       "      <td>0.359093</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.469023</td>\n",
       "      <td>12.978661</td>\n",
       "      <td>3.602591</td>\n",
       "      <td>-11.220044</td>\n",
       "      <td>0.385845</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.451814</td>\n",
       "      <td>13.564143</td>\n",
       "      <td>3.682953</td>\n",
       "      <td>-8.939270</td>\n",
       "      <td>0.110938</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.326988</td>\n",
       "      <td>13.063471</td>\n",
       "      <td>3.614342</td>\n",
       "      <td>-3.275856</td>\n",
       "      <td>0.595319</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.231633</td>\n",
       "      <td>11.831097</td>\n",
       "      <td>3.439636</td>\n",
       "      <td>-5.185799</td>\n",
       "      <td>0.524591</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.400032</td>\n",
       "      <td>12.657605</td>\n",
       "      <td>3.557753</td>\n",
       "      <td>-8.722722</td>\n",
       "      <td>0.396396</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.461685</td>\n",
       "      <td>13.245359</td>\n",
       "      <td>3.639417</td>\n",
       "      <td>-9.306330</td>\n",
       "      <td>0.269751</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.313756</td>\n",
       "      <td>12.056391</td>\n",
       "      <td>3.472231</td>\n",
       "      <td>-9.650402</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.503661</td>\n",
       "      <td>13.608536</td>\n",
       "      <td>3.688975</td>\n",
       "      <td>-6.715335</td>\n",
       "      <td>0.495004</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.659311</td>\n",
       "      <td>14.603194</td>\n",
       "      <td>3.821413</td>\n",
       "      <td>-12.043471</td>\n",
       "      <td>0.253097</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.463913</td>\n",
       "      <td>12.981046</td>\n",
       "      <td>3.602922</td>\n",
       "      <td>-11.558307</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.257842</td>\n",
       "      <td>12.043954</td>\n",
       "      <td>3.470440</td>\n",
       "      <td>-5.536316</td>\n",
       "      <td>0.473504</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.484513</td>\n",
       "      <td>13.298338</td>\n",
       "      <td>3.646689</td>\n",
       "      <td>-7.752944</td>\n",
       "      <td>0.509521</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.305750</td>\n",
       "      <td>12.330653</td>\n",
       "      <td>3.511503</td>\n",
       "      <td>-10.097133</td>\n",
       "      <td>0.176116</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.386571</td>\n",
       "      <td>13.382858</td>\n",
       "      <td>3.658259</td>\n",
       "      <td>-4.888463</td>\n",
       "      <td>0.398559</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.473207</td>\n",
       "      <td>13.423412</td>\n",
       "      <td>3.663797</td>\n",
       "      <td>-6.732381</td>\n",
       "      <td>0.465904</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.132319</td>\n",
       "      <td>11.541837</td>\n",
       "      <td>3.397328</td>\n",
       "      <td>-5.341657</td>\n",
       "      <td>0.274108</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.502156</td>\n",
       "      <td>13.418848</td>\n",
       "      <td>3.663175</td>\n",
       "      <td>-13.859991</td>\n",
       "      <td>0.251666</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.470302</td>\n",
       "      <td>13.711441</td>\n",
       "      <td>3.702896</td>\n",
       "      <td>-7.530074</td>\n",
       "      <td>0.248698</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.381027</td>\n",
       "      <td>12.943304</td>\n",
       "      <td>3.597680</td>\n",
       "      <td>-7.157635</td>\n",
       "      <td>0.311212</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.425926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.181247</td>\n",
       "      <td>11.469937</td>\n",
       "      <td>3.386729</td>\n",
       "      <td>-7.117519</td>\n",
       "      <td>0.308927</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.436364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.260358</td>\n",
       "      <td>11.981905</td>\n",
       "      <td>3.461489</td>\n",
       "      <td>-4.490789</td>\n",
       "      <td>0.624668</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.380751</td>\n",
       "      <td>12.465626</td>\n",
       "      <td>3.530669</td>\n",
       "      <td>-6.631533</td>\n",
       "      <td>0.628706</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.491972</td>\n",
       "      <td>13.435669</td>\n",
       "      <td>3.665470</td>\n",
       "      <td>-10.333092</td>\n",
       "      <td>0.289460</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.391154</td>\n",
       "      <td>13.162504</td>\n",
       "      <td>3.628016</td>\n",
       "      <td>-6.734688</td>\n",
       "      <td>0.262640</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.297935</td>\n",
       "      <td>11.825480</td>\n",
       "      <td>3.438820</td>\n",
       "      <td>-9.392833</td>\n",
       "      <td>0.408073</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rf</td>\n",
       "      <td>3.598709</td>\n",
       "      <td>14.720234</td>\n",
       "      <td>3.836696</td>\n",
       "      <td>-5.741836</td>\n",
       "      <td>0.437853</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.433962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model       MAE        MSE      RMSE         R2  Pearson_Correlation  \\\n",
       "0     rf  3.348017  12.649644  3.556634  -7.243906             0.311026   \n",
       "1     rf  3.470257  13.222314  3.636250  -9.443264             0.326711   \n",
       "2     rf  3.448496  13.310552  3.648363 -10.192320             0.149196   \n",
       "3     rf  3.314047  12.410373  3.522836  -7.177222             0.359093   \n",
       "4     rf  3.469023  12.978661  3.602591 -11.220044             0.385845   \n",
       "5     rf  3.451814  13.564143  3.682953  -8.939270             0.110938   \n",
       "6     rf  3.326988  13.063471  3.614342  -3.275856             0.595319   \n",
       "7     rf  3.231633  11.831097  3.439636  -5.185799             0.524591   \n",
       "8     rf  3.400032  12.657605  3.557753  -8.722722             0.396396   \n",
       "9     rf  3.461685  13.245359  3.639417  -9.306330             0.269751   \n",
       "10    rf  3.313756  12.056391  3.472231  -9.650402             0.400189   \n",
       "11    rf  3.503661  13.608536  3.688975  -6.715335             0.495004   \n",
       "12    rf  3.659311  14.603194  3.821413 -12.043471             0.253097   \n",
       "13    rf  3.463913  12.981046  3.602922 -11.558307             0.290100   \n",
       "14    rf  3.257842  12.043954  3.470440  -5.536316             0.473504   \n",
       "15    rf  3.484513  13.298338  3.646689  -7.752944             0.509521   \n",
       "16    rf  3.305750  12.330653  3.511503 -10.097133             0.176116   \n",
       "17    rf  3.386571  13.382858  3.658259  -4.888463             0.398559   \n",
       "18    rf  3.473207  13.423412  3.663797  -6.732381             0.465904   \n",
       "19    rf  3.132319  11.541837  3.397328  -5.341657             0.274108   \n",
       "20    rf  3.502156  13.418848  3.663175 -13.859991             0.251666   \n",
       "21    rf  3.470302  13.711441  3.702896  -7.530074             0.248698   \n",
       "22    rf  3.381027  12.943304  3.597680  -7.157635             0.311212   \n",
       "23    rf  3.181247  11.469937  3.386729  -7.117519             0.308927   \n",
       "24    rf  3.260358  11.981905  3.461489  -4.490789             0.624668   \n",
       "25    rf  3.380751  12.465626  3.530669  -6.631533             0.628706   \n",
       "26    rf  3.491972  13.435669  3.665470 -10.333092             0.289460   \n",
       "27    rf  3.391154  13.162504  3.628016  -6.734688             0.262640   \n",
       "28    rf  3.297935  11.825480  3.438820  -9.392833             0.408073   \n",
       "29    rf  3.598709  14.720234  3.836696  -5.741836             0.437853   \n",
       "\n",
       "    Accuracy  F1-Score  \n",
       "0   0.741935  0.425926  \n",
       "1   0.741935  0.425926  \n",
       "2   0.741935  0.425926  \n",
       "3   0.774194  0.436364  \n",
       "4   0.766667  0.433962  \n",
       "5   0.766667  0.433962  \n",
       "6   0.766667  0.433962  \n",
       "7   0.766667  0.433962  \n",
       "8   0.766667  0.433962  \n",
       "9   0.766667  0.433962  \n",
       "10  0.741935  0.425926  \n",
       "11  0.741935  0.425926  \n",
       "12  0.741935  0.425926  \n",
       "13  0.774194  0.436364  \n",
       "14  0.766667  0.433962  \n",
       "15  0.766667  0.433962  \n",
       "16  0.766667  0.433962  \n",
       "17  0.766667  0.433962  \n",
       "18  0.766667  0.433962  \n",
       "19  0.766667  0.433962  \n",
       "20  0.741935  0.425926  \n",
       "21  0.741935  0.425926  \n",
       "22  0.741935  0.425926  \n",
       "23  0.774194  0.436364  \n",
       "24  0.766667  0.433962  \n",
       "25  0.766667  0.433962  \n",
       "26  0.766667  0.433962  \n",
       "27  0.766667  0.433962  \n",
       "28  0.766667  0.433962  \n",
       "29  0.766667  0.433962  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.val_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9157e3d-d953-4fe8-977d-5709dc06397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Pearson_Correlation</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.983521</td>\n",
       "      <td>1.400372</td>\n",
       "      <td>1.183373</td>\n",
       "      <td>-0.005724</td>\n",
       "      <td>0.240549</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model       MAE       MSE      RMSE        R2  Pearson_Correlation  \\\n",
       "0    rf  0.983521  1.400372  1.183373 -0.005724             0.240549   \n",
       "\n",
       "   Accuracy  F1-Score  \n",
       "0  0.705882  0.413793  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml.test_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07decc83-a306-490f-a530-2960328a1cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'XGBoost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mXGBoost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/Mac/Desktop/Autoimmune_Disease/Code/ML_RA_EHR/ModelModule/../EvaluationModule.py:414\u001b[0m, in \u001b[0;36mAutoBuild.confusion_matrix\u001b[0;34m(self, model_id, plot, normalize)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_id, plot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 414\u001b[0m     true, pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28mprint\u001b[39m(pred\u001b[38;5;241m.\u001b[39mvalue_counts())\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'XGBoost'"
     ]
    }
   ],
   "source": [
    "aml.confusion_matrix(\"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3a37e-6476-4184-a38a-5a4ce23b2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aml.confusion_matrix(\"Linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d52f31-5977-47fa-a163-a4afe25b8450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADPred_new",
   "language": "python",
   "name": "adpred_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
