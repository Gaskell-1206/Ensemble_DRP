{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from DataModule.Data_Preparation import CoronnaCERTAINDataset\n",
    "import EvaluationModule\n",
    "import ModelModule.models\n",
    "import pickle\n",
    "import sklearn \n",
    "from sklearn.model_selection import (KFold, RepeatedKFold,\n",
    "                                     RepeatedStratifiedKFold, ShuffleSplit,\n",
    "                                     StratifiedKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'hist', 'reg_lambda': 0.7000000000000001, 'n_estimators': 300, 'min_child_weight': 4, 'max_depth': 1, 'max_delta_step': 6, 'gamma': 7, 'eta': 0.7000000000000001, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.5}\n",
      "base LinearDone\n",
      "best_params: {'normalize': False, 'fit_intercept': True}\n",
      "base LassoDone\n",
      "best_params: {'selection': 'random', 'normalize': True, 'max_iter': 1000, 'fit_intercept': True, 'alpha': 25}\n",
      "base RidgeDone\n",
      "best_params: {'solver': 'lsqr', 'normalize': True, 'fit_intercept': True, 'alpha': 10}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'sgd', 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'batch_size': 40, 'alpha': 0.3, 'activation': 'tanh'}\n",
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'approx', 'reg_lambda': 0.2, 'n_estimators': 1000, 'min_child_weight': 8, 'max_depth': 3, 'max_delta_step': 5, 'gamma': 5, 'eta': 0.6, 'colsample_bytree': 0.6, 'colsample_bylevel': 0.7}\n",
      "base LinearDone\n",
      "best_params: {'normalize': False, 'fit_intercept': True}\n",
      "base LassoDone\n",
      "best_params: {'selection': 'random', 'normalize': True, 'max_iter': 1250, 'fit_intercept': True, 'alpha': 25}\n",
      "base RidgeDone\n",
      "best_params: {'solver': 'sag', 'normalize': True, 'fit_intercept': True, 'alpha': 10}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'sgd', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100,), 'batch_size': 60, 'alpha': 0.001, 'activation': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_search_grid={\n",
    "\"Random forest\": {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    " },\n",
    "\n",
    "\"XGBoost\":dict(\n",
    "eta =np.arange(.1,1.1,.1),\n",
    "gamma =np.arange(1,10,1), \n",
    "max_depth=np.arange(1,20,2),\n",
    "min_child_weight= np.arange(1,10,1),\n",
    "max_delta_step= np.arange(1,10,1),\n",
    "reg_lambda = np.arange(.1,1.1,.1),\n",
    "colsample_bytree= np.arange(0.4, 1.0, 0.1),\n",
    "colsample_bylevel= np.arange(0.4, 1.0, 0.1),\n",
    "n_estimators=np.arange(100, 1100, 100),\n",
    "tree_method =['auto', 'exact', 'approx', 'hist', 'gpu_hist'],\n",
    ")\n",
    ",\n",
    "\"Linear\": dict(\n",
    "normalize=[True,False],\n",
    "fit_intercept=[True,False],\n",
    ")\n",
    ",\n",
    "\"Ridge\": dict(\n",
    "alpha=[0,1,5,10,20,25,50,100],\n",
    "normalize=[True,False],\n",
    "fit_intercept=[True,False],\n",
    "solver=['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga','lbfgs']\n",
    "),\n",
    "\"Lasso\": dict(\n",
    "alpha=[0,1,5,10,20,25,50,100],\n",
    "max_iter=[500,750,1000,1250,1500,2000],\n",
    "normalize=[True,False],\n",
    "fit_intercept=[True,False],\n",
    "selection=['cyclic', 'random']\n",
    ")\n",
    ",\n",
    "\n",
    "\n",
    "\n",
    "# \"SVM\": dict(\n",
    "# C = np.logspace(-1, 1, 3),\n",
    "# kernel=[ 'poly', 'rbf', 'sigmoid'] ,\n",
    "# gamma = np.logspace(-1, 1, 3),\n",
    "# shrinking=[True,False]\n",
    "\n",
    "# )\n",
    "#,\n",
    "\"ANN\": dict(\n",
    "solver=['lbfgs', 'sgd', 'adam'],\n",
    "batch_size = [10, 20, 40, 60, 80, 100],\n",
    "learning_rate= ['constant','adaptive'], \n",
    "hidden_layer_sizes= [(50,50,50), (50,100,50), (100,)],\n",
    "activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "alpha=[0.0001,0.001, 0.01, 0.1, 0.2, 0.3]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "dataset_params=[\n",
    "        # dict(\n",
    "        # library_root=\"../Dataset/\",\n",
    "        # challenge='regression', #option: regression, regression_delta, classification, binary_classification\n",
    "        # dataset='CORRONA CERTAIN', \n",
    "        # process_approach='SC', #option: KVB, SC\n",
    "        # imputation=\"IterativeImputer\", #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "        # patient_group=['bionaive TNF'], #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "        # drug_group='all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "        # time_points=(0,3), \n",
    "        # train_test_rate=0.8,\n",
    "        # remove_low_DAS = True,\n",
    "        # save_csv=True,\n",
    "        # random_state=2022),\n",
    "         dict(\n",
    "        library_root=\"../Dataset/\",\n",
    "        challenge='regression_delta', #option: regression, regression_delta, classification, binary_classification\n",
    "        dataset='CORRONA CERTAIN', \n",
    "        process_approach='SC', #option: KVB, SC\n",
    "        imputation=\"IterativeImputer\", #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "        patient_group=['bionaive TNF'], #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "        drug_group='all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "        time_points=(0,3), \n",
    "        train_test_rate=0.8,\n",
    "        remove_low_DAS = True,\n",
    "        save_csv=True,\n",
    "        random_state=2022),\n",
    "        dict(\n",
    "        library_root=\"../Dataset/\",\n",
    "        challenge='regression_delta_binary', #option: regression, regression_delta, classification, binary_classification\n",
    "        dataset='CORRONA CERTAIN', \n",
    "        process_approach='SC', #option: KVB, SC\n",
    "        imputation=\"IterativeImputer\", #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "        patient_group=['bionaive TNF'], #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "        drug_group='all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "        time_points=(0,3), \n",
    "        train_test_rate=0.8,\n",
    "        remove_low_DAS = True,\n",
    "        save_csv=True,\n",
    "        random_state=2022)\n",
    "        ]\n",
    "base_estimators={\n",
    "\"Random forest\":dict(model_id=\"Random forest\", model_list=[\"Random Forest\"], challenge=\"Regression\"),\n",
    "\"XGBoost\":dict(model_id=\"XGBoost\", model_list=[\"XGBoost\"], challenge=\"Regression\"),\n",
    "\"Linear\":dict(model_id=\"Linear\", model_list=[\"Linear\"], challenge=\"Regression\"),\n",
    "\"Lasso\":dict(model_id=\"Lasso\", model_list=[\"Lasso\"], challenge=\"Regression\"),\n",
    "\"Ridge\":dict(model_id=\"Ridge\", model_list=[\"Ridge\"], challenge=\"Regression\"),\n",
    "\n",
    "\n",
    "\n",
    "#\"SVM\":dict(model_id=\"SVM\", model_list=[\"SVM\"], challenge=\"Regression\"),\n",
    "\n",
    "\"ANN\":dict(model_id=\"ANN\", model_list=[\"ANN\"], challenge=\"Regression\")\n",
    "\n",
    "\n",
    "}\n",
    "aml=ModelModule.models.tune_models(dataset_parms=dataset_params,fixed_model_params=base_estimators, test_model_parms=param_search_grid, method='random', project_name=\"regression_testing\",ballance_class=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': True}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'auto', 'reg_lambda': 0.6, 'n_estimators': 200, 'min_child_weight': 6, 'max_depth': 5, 'max_delta_step': 5, 'gamma': 3, 'eta': 0.6, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.4}\n",
      "base LogisticDone\n",
      "best_params: {'solver': 'newton-cg', 'penalty': 'none', 'max_iter': 100, 'fit_intercept': False, 'dual': False, 'C': 545.5594781168514}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'lbfgs', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50, 50), 'batch_size': 100, 'alpha': 0.1, 'activation': 'tanh'}\n",
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 600, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'auto', 'reg_lambda': 0.8, 'n_estimators': 100, 'min_child_weight': 6, 'max_depth': 19, 'max_delta_step': 8, 'gamma': 2, 'eta': 0.5, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.7}\n",
      "base LogisticDone\n",
      "best_params: {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 2500, 'fit_intercept': True, 'dual': False, 'C': 0.615848211066026}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 50, 50), 'batch_size': 10, 'alpha': 0.3, 'activation': 'logistic'}\n",
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 80, 'bootstrap': False}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'auto', 'reg_lambda': 0.1, 'n_estimators': 100, 'min_child_weight': 2, 'max_depth': 19, 'max_delta_step': 5, 'gamma': 2, 'eta': 0.1, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.4}\n",
      "base LogisticDone\n",
      "best_params: {'solver': 'newton-cg', 'penalty': 'none', 'max_iter': 5000, 'fit_intercept': False, 'dual': False, 'C': 0.03359818286283781}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'lbfgs', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 100, 50), 'batch_size': 60, 'alpha': 0.1, 'activation': 'tanh'}\n",
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'approx', 'reg_lambda': 0.7000000000000001, 'n_estimators': 300, 'min_child_weight': 7, 'max_depth': 19, 'max_delta_step': 3, 'gamma': 3, 'eta': 0.9, 'colsample_bytree': 0.7999999999999999, 'colsample_bylevel': 0.7}\n",
      "base LogisticDone\n",
      "best_params: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 100, 'fit_intercept': True, 'dual': False, 'C': 545.5594781168514}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'sgd', 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'batch_size': 100, 'alpha': 0.2, 'activation': 'logistic'}\n",
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 600, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 30, 'bootstrap': False}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'auto', 'reg_lambda': 0.5, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 5, 'max_delta_step': 2, 'gamma': 3, 'eta': 0.30000000000000004, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.7}\n",
      "base LogisticDone\n",
      "best_params: {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 2500, 'fit_intercept': False, 'dual': False, 'C': 10000.0}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'sgd', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 100, 50), 'batch_size': 40, 'alpha': 0.2, 'activation': 'tanh'}\n",
      "base Random ForestDone\n",
      "best_params: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n",
      "base XGBoostDone\n",
      "best_params: {'tree_method': 'exact', 'reg_lambda': 0.6, 'n_estimators': 800, 'min_child_weight': 2, 'max_depth': 13, 'max_delta_step': 2, 'gamma': 3, 'eta': 0.1, 'colsample_bytree': 0.4, 'colsample_bylevel': 0.8999999999999999}\n",
      "base LogisticDone\n",
      "best_params: {'solver': 'saga', 'penalty': 'none', 'max_iter': 100, 'fit_intercept': True, 'dual': False, 'C': 0.23357214690901212}\n",
      "base ANNDone\n",
      "best_params: {'solver': 'adam', 'learning_rate': 'constant', 'hidden_layer_sizes': (50, 50, 50), 'batch_size': 10, 'alpha': 0.3, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "param_search_grid={\n",
    "\"Random forest\": {'bootstrap': [True, False],\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " 'min_samples_split': [2, 5, 10],\n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n",
    " },\n",
    "\n",
    "\"XGBoost\":dict(\n",
    "eta =np.arange(.1,1.1,.1),\n",
    "gamma =np.arange(1,10,1), \n",
    "max_depth=np.arange(1,20,2),\n",
    "min_child_weight= np.arange(1,10,1),\n",
    "max_delta_step= np.arange(1,10,1),\n",
    "reg_lambda = np.arange(.1,1.1,.1),\n",
    "colsample_bytree= np.arange(0.4, 1.0, 0.1),\n",
    "colsample_bylevel= np.arange(0.4, 1.0, 0.1),\n",
    "n_estimators=np.arange(100, 1100, 100),\n",
    "tree_method =['auto', 'exact', 'approx', 'hist', 'gpu_hist'],\n",
    "),\n",
    "\"Logistic\": dict(\n",
    "penalty=['l1', 'l2', 'elasticnet', 'none'],\n",
    "dual=[True,False],\n",
    "C = np.logspace(-4, 4, 20),   \n",
    "max_iter = [100, 1000,2500, 5000],\n",
    "fit_intercept=[True,False],\n",
    "solver=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "#),\n",
    "# \"SVM\": dict(\n",
    "# C = np.logspace(-4, 4, 20),\n",
    "# kernel=['linear', 'poly', 'rbf', 'sigmoid'] ,\n",
    "# gamma =[1, 0.1, 0.01, 0.001, 0.0001],\n",
    "# shrinking=[True,False]\n",
    "\n",
    "# ),\n",
    "\"ANN\": dict(\n",
    "solver=['lbfgs', 'sgd', 'adam'],\n",
    "batch_size = [10, 20, 40, 60, 80, 100],\n",
    "learning_rate= ['constant','adaptive'], \n",
    "hidden_layer_sizes= [(50,50,50), (50,100,50), (100,)],\n",
    "activation=['identity', 'logistic', 'tanh', 'relu'],\n",
    "alpha=[0.0001,0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "dataset_params=[\n",
    "        dict(\n",
    "        library_root=\"../Dataset/\",\n",
    "        challenge='classification', #option: regression, regression_delta, classification, binary_classification\n",
    "        dataset='CORRONA CERTAIN', \n",
    "        process_approach='SC', #option: KVB, SC\n",
    "        imputation=\"IterativeImputer\", #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "        patient_group=['bionaive TNF'], #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "        drug_group='all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "        time_points=(0,3), \n",
    "        train_test_rate=0.8,\n",
    "        remove_low_DAS = True,\n",
    "        save_csv=True,\n",
    "        random_state=2022),\n",
    "         dict(\n",
    "        library_root=\"../Dataset/\",\n",
    "        challenge='binary_classification', #option: regression, regression_delta, classification, binary_classification\n",
    "        dataset='CORRONA CERTAIN', \n",
    "        process_approach='SC', #option: KVB, SC\n",
    "        imputation=\"IterativeImputer\", #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "        patient_group=['bionaive TNF'], #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "        drug_group='all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "        time_points=(0,3), \n",
    "        train_test_rate=0.8,\n",
    "        remove_low_DAS = True,\n",
    "        save_csv=True,\n",
    "        random_state=2022)\n",
    "        ]\n",
    "base_estimators={\n",
    "\"Random forest\":dict(model_id=\"Random forest\", model_list=[\"Random Forest\"], challenge=\"Classification\"),\n",
    "\"XGBoost\":dict(model_id=\"XGBoost\", model_list=[\"XGBoost\"], challenge=\"Classification\"),\n",
    "\"Logistic\":dict(model_id=\"Logistic\", model_list=[\"Logistic\"], challenge=\"Classification\"),\n",
    "#\"SVM\":dict(model_id=\"SVM\", model_list=[\"SVM\"], challenge=\"Classification\"),\n",
    "\"ANN\":dict(model_id=\"ANN\", model_list=[\"ANN\"], challenge=\"Classification\")\n",
    "\n",
    "\n",
    "}\n",
    "aml=ModelModule.models.tune_models(dataset_parms=dataset_params,fixed_model_params=base_estimators, test_model_parms=param_search_grid, method='random', project_name=\"classfication_testing\",ballance_class=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learners=[ \"Bayes\", 'Logistic', \"SVM\", 'ANN','XGBoost','Random Forest', 'Tree']\n",
    "from itertools import chain, combinations\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r+1) for r in range(len(s)))\n",
    "estemators=[list(c) for c in list(powerset(meta_learners))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml=EvaluationModule.AutoBuild(seed=1,challenge='binary_classification')\n",
    "parameters= {'ensamble_type':[\"Stacking\"],'model_list':estemators, 'challange':['Classification'], 'meta_learner':meta_learners}\n",
    "ensamble_model.test_hyper_parameters(parameters,train,test,dataset,aml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b76f26fa8a612c8b8cb65ddaeb140f1392e886a532c01d32a03fb4eb587cde30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
