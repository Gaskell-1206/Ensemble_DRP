{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'C:\\Users\\buzga\\Desktop\\School\\Reaserch\\Langone\\ML_RA_EHR\\DataModule')\n",
    "sys.path.insert(0, r'C:\\Users\\buzga\\Desktop\\School\\Reaserch\\Langone\\ML_RA_EHR')\n",
    "sys.path.insert(0, r'C:\\Users\\buzga\\Desktop\\School\\Reaserch\\Langone\\ML_RA_EHR\\EnsambleModule')\n",
    "import Data_Preparation\n",
    "import EvaluationModule \n",
    "import ensamble_model \n",
    "import sklearn\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature engineering, drop columns due to 70% missing value: Index(['smkyrs', 'numcigs', 'rfstatus_impute', 'ccpstatus_impute',\n",
      "       'statin_use'],\n",
      "      dtype='object')\n",
      "Missing values in train before imputation: 128\n",
      "Missing values in train after imputation: 0\n",
      "Missing values in test before imputation: 24\n",
      "Missing values in test after imputation: 0\n",
      "Label Encoder, 0: Non-responders (No Response), 1: Responders(Good, Moderate)\n",
      "save file to: C:\\Users\\buzga\\Desktop\\School\\Reaserch\\Langone\\ML_RA_EHR\\Dataset\\Coronna_Data_CERTAIN_binary_classification_SC_0M_3M_bionaive TNF_all\\Train.csv\n",
      "Label Encoder, 0: Non-responders (No Response), 1: Responders(Good, Moderate)\n",
      "save file to: C:\\Users\\buzga\\Desktop\\School\\Reaserch\\Langone\\ML_RA_EHR\\Dataset\\Coronna_Data_CERTAIN_binary_classification_SC_0M_3M_bionaive TNF_all\\Test.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r'C:\\Users\\buzga\\Desktop\\School\\Reaserch\\Langone\\ML_RA_EHR\\Dataset'\n",
    "dataset = Data_Preparation.CoronnaCERTAINDataset(\n",
    "    library_root=path,\n",
    "    challenge=\"binary_classification\", #option: regression, regression_delta, classification, binary_classification\n",
    "    dataset='CORRONA CERTAIN', \n",
    "    process_approach='SC', #option: KVB, SC\n",
    "    imputation=\"IterativeImputer\", #option: SimpleFill, KNN, SoftImpute, BiScaler, NuclearNormMinimization, IterativeImputer, IterativeSVD, None(raw)\n",
    "    patient_group='bionaive TNF', #option: \"all\", \"bioexp nTNF\", \"bionaive TNF\", \"bionaive orencia\", \"KVB\"\n",
    "    drug_group='all', #option: \"all\", \"actemra\", \"cimzia\", \"enbrel\", \"humira\", \"orencia\", \"remicade\", \"rituxan\", \"simponi\"\n",
    "    time_points=(0,3), \n",
    "    train_test_rate=0.8,\n",
    "    remove_low_DAS = True,\n",
    "    save_csv=True,\n",
    "    random_state=2022)\n",
    "\n",
    "\n",
    "\n",
    "train, train_loc = dataset.get_train()\n",
    "test, test_loc = dataset.get_test()\n",
    "\n",
    "\n",
    "## train test split \n",
    "X_train = train.iloc[:,:-1]\n",
    "y_train = train.iloc[:,-1]\n",
    "X_test = test.iloc[:,:-1]\n",
    "\n",
    "y_test = test.iloc[:,-1]\n",
    "len(y_test)+len(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learners=[ \"Bayes\", 'Logistic', \"SVM\", 'ANN','XGBoost','Random Forest', 'Tree']\n",
    "from itertools import chain, combinations\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r+1) for r in range(len(s)))\n",
    "estemators=[list(c) for c in list(powerset(meta_learners))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|â–‰         | 80/889 [09:53<2:16:08, 10.10s/it]"
     ]
    }
   ],
   "source": [
    "aml=EvaluationModule.AutoBuild(seed=1,challenge='binary_classification')\n",
    "parameters= {'ensamble_type':[\"Stacking\"],'model_list':estemators, 'challange':['Classification'], 'meta_learner':meta_learners}\n",
    "ensamble_model.test_hyper_parameters(parameters,train,test,dataset,aml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b76f26fa8a612c8b8cb65ddaeb140f1392e886a532c01d32a03fb4eb587cde30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
